{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Challenge\n",
    "Goal: to capture the complexity and nuances around the evolution of the pandemic at various stages and locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider the following settings:\n",
    "1. *Timepoint 1*: May 1st, 2020. Setting: Michigan State at the beginning of the pandemic when masking was the main preventative measure. No vaccines available.\n",
    "2. *Timepoint 2*: May 1st, 2021. Setting: Michigan State prior to the arrival of the Delta variant. Vaccines available.\n",
    "3. *Timepoint 3*: December 15th, 2021. Setting: Michigan State during the start of the first Omicron wave.\n",
    "\n",
    "4. *BONUS*: Consider the same three time points, but change the setting to Louisiana, which had different COVID-19 dynamics compared to the Northern and Northeastern states.\n",
    "\n",
    "## ...and related questions for each:\n",
    "1. What is the most relevant data to use for model calibration?\n",
    "2. What was our understanding of COVID-19 viral mechanisms at the time? For example, early in the pandemic, we didn't know if reinfection was a common occurance, or even possible.\n",
    "3. What are the parameters related to contagiousness/transmissibility and severity of the dominant strain at the time?\n",
    "4. What policies were in place for a stated location, and how can this information be incorporated into models? (See https://www.bsg.ox.ac.uk/research/covid-19-government-response-tracker for time series of interventions.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each setting:\n",
    "1. (a) Take a single model, calibrate it using historical data prior to the given date, and create a 4-week forecast for cases, hospitalizations, and deaths beginning on the given date. (b) Evaluate the forecast using the COVID-19 Forecasting Hub Error Metrics (WIS, MAE). The single model evaluation should be done in the same way as the ensemble.\n",
    "\n",
    "2. Repeat (1), but with an ensemble of different models.\n",
    "\n",
    "    a. It is fine to calibrate each model independently and weight naively.\n",
    "    \n",
    "    b. It would also be fine to calibrate the ensemble as a whole, assigning weights to the different component models, so that you minimize the error of the ensemble vs. historical data.\n",
    "    \n",
    "    c. Use the calibration scores and error metrics computed by the CDC Forecasting Hub. As stated on their [website](https://covid19forecasthub.org/doc/reports/): \n",
    "    \n",
    "    “Periodically, we evaluate the accuracy and precision of the [ensemble forecast](https://covid19forecasthub.org/doc/ensemble/) and component models over recent and historical forecasting periods. Models forecasting incident hospitalizations at a national and state level are evaluated using [adjusted relative weighted interval scores (WIS, a measure of distributional accuracy)](https://arxiv.org/abs/2005.12881), and adjusted relative mean absolute error (MAE), and calibration scores. Scores are evaluated across weeks, locations, and targets. You can read [a paper explaining these procedures in more detail](https://www.medrxiv.org/content/10.1101/2021.02.03.21250974v1), and look at [the most recent monthly evaluation reports](https://covid19forecasthub.org/eval-reports). The final report that includes case and death forecast evaluations is 2023-03-13.” \n",
    "\n",
    "3. Produce the forecast outputs in the format specified by the CDC forecasting challenge, including the specified quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Use the following data sources:\n",
    "1. Cases: [Johns Hopkins](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv), [Reich Lab](https://github.com/reichlab/covid19-forecast-hub/blob/master/data-truth/truth-Incident%20Cases.csv) (pulled from Johns Hopkins, but formatted)\n",
    "\n",
    "2. Hospitalizations: [HealthData.gov](https://healthdata.gov/Hospital/COVID-19-Reported-Patient-Impact-and-Hospital-Capa/g62h-syeh)\n",
    "\n",
    "3. Deaths: [Johns Hopkins](https://github.com/reichlab/covid19-forecast-hub/blob/master/data-truth/truth-Incident%20Deaths.csv), [Reich Lab](https://github.com/reichlab/covid19-forecast-hub/blob/master/data-truth/truth-Cumulative%20Deaths.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inital dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_regions = ['US', 'AL', 'AK', 'Skip', 'AZ', 'AR', 'CA', 'Skip 2', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'Skip 3', \n",
    "                'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', \n",
    "                'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'Skip 4', 'RI', 'SC', 'SD', 'TN', \n",
    "                'TX', 'UT', 'VT', 'VA', 'Skip 5', 'WA', 'WV', 'WI', 'WY']\n",
    "fips_dict = {state: fips for state, fips in zip(US_regions, range(0, 100))}\n",
    "fips_dict[\"US\"] = \"US\"\n",
    "\n",
    "def get_fips(US_region):\n",
    "    '''This function returns the 1 or 2 digit FIPS code corresponding to the 2-letter state abbreviation.\n",
    "    \n",
    "    :param US_state: 2-letter state abbreviation as a string\n",
    "    :returns: 1 or 2 digit FIPS code as a string\n",
    "    '''\n",
    "    return str(fips_dict[US_region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/2542200153.py:8: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_cases = pd.read_csv(url)\n",
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/2542200153.py:9: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  raw_cases['date'] = pd.to_datetime(raw_cases.date, infer_datetime_format = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date location      location_name  value\n",
      "0       2020-01-22     1001     Autauga County      0\n",
      "233290  2020-01-22     6035      Lassen County      0\n",
      "2642436 2020-01-22    45011    Barnwell County      0\n",
      "2643574 2020-01-22    45013    Beaufort County      0\n",
      "2644712 2020-01-22    45015    Berkeley County      0\n",
      "...            ...      ...                ...    ...\n",
      "2421663 2023-03-04    39167  Washington County      0\n",
      "2420525 2023-03-04    39165      Warren County      0\n",
      "2419387 2023-03-04    39163      Vinton County      0\n",
      "2417111 2023-03-04    39159       Union County      0\n",
      "3641599 2023-03-04       US      United States   1932\n",
      "\n",
      "[3641600 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/2542200153.py:16: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  raw_hosp['date'] = pd.to_datetime(raw_hosp.date, infer_datetime_format = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date location  location_name  value\n",
      "22879 2020-01-01       32         Nevada    132\n",
      "15087 2020-01-02       32         Nevada    132\n",
      "22516 2020-01-03       05       Arkansas      0\n",
      "16863 2020-01-03       32         Nevada    132\n",
      "23474 2020-01-04       32         Nevada    132\n",
      "...          ...      ...            ...    ...\n",
      "22372 2023-06-30       04        Arizona     16\n",
      "28066 2023-06-30       26       Michigan     27\n",
      "22547 2023-06-30       24       Maryland     10\n",
      "17407 2023-06-30       47      Tennessee      8\n",
      "59329 2023-06-30       US  United States    879\n",
      "\n",
      "[59330 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/2542200153.py:22: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_deaths = pd.read_csv(url)\n",
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/2542200153.py:23: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  raw_deaths['date'] = pd.to_datetime(raw_deaths.date, infer_datetime_format = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date location      location_name    value\n",
      "0       2020-01-22     1001     Autauga County        0\n",
      "233290  2020-01-22     6035      Lassen County        0\n",
      "2642436 2020-01-22    45011    Barnwell County        0\n",
      "2643574 2020-01-22    45013    Beaufort County        0\n",
      "2644712 2020-01-22    45015    Berkeley County        0\n",
      "...            ...      ...                ...      ...\n",
      "2421663 2023-03-04    39167  Washington County      247\n",
      "2420525 2023-03-04    39165      Warren County      646\n",
      "2419387 2023-03-04    39163      Vinton County       60\n",
      "2417111 2023-03-04    39159       Union County      117\n",
      "3641599 2023-03-04       US      United States  1122164\n",
      "\n",
      "[3641600 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Set region and infectious period\n",
    "US_region = \"MI\"\n",
    "fips_code = get_fips(US_region)\n",
    "infectious_period = 7\n",
    "\n",
    "# Get incident case data (by county) and sort by date\n",
    "url = 'https://media.githubusercontent.com/media/reichlab/covid19-forecast-hub/master/data-truth/truth-Incident%20Cases.csv'\n",
    "raw_cases = pd.read_csv(url)\n",
    "raw_cases['date'] = pd.to_datetime(raw_cases.date, infer_datetime_format = True)\n",
    "raw_cases.sort_values(by = 'date', ascending = True, inplace = True)\n",
    "print(raw_cases)\n",
    "\n",
    "# Get hosp census data (by state) and sort by date\n",
    "url = 'https://media.githubusercontent.com/media/reichlab/covid19-forecast-hub/master/data-truth/truth-Incident%20Hospitalizations.csv'\n",
    "raw_hosp = pd.read_csv(url)\n",
    "raw_hosp['date'] = pd.to_datetime(raw_hosp.date, infer_datetime_format = True)\n",
    "raw_hosp.sort_values(by = 'date', ascending = True, inplace = True)\n",
    "print(raw_hosp)\n",
    "\n",
    "# Get cumulative death data (by county) and sort by date\n",
    "url = 'https://media.githubusercontent.com/media/reichlab/covid19-forecast-hub/master/data-truth/truth-Cumulative%20Deaths.csv'\n",
    "raw_deaths = pd.read_csv(url)\n",
    "raw_deaths['date'] = pd.to_datetime(raw_deaths.date, infer_datetime_format = True)\n",
    "raw_deaths.sort_values(by = 'date', ascending = True, inplace = True)\n",
    "print(raw_deaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data for the given region\n",
    "regional_hosp = raw_hosp[raw_hosp[\"location\"] == fips_code]\n",
    "if fips_code == \"US\":\n",
    "    regional_cases = raw_cases[raw_cases[\"location\"] == \"US\"]\n",
    "    regional_deaths = raw_deaths[raw_deaths[\"location\"] == \"US\"]\n",
    "elif len(fips_code) == 1:\n",
    "    regional_cases = raw_cases[(raw_cases[\"location\"].astype(str).str.len() == 4.0) & (raw_cases[\"location\"].astype(str).str[:1] == fips_code)]\n",
    "    regional_deaths = raw_deaths[(raw_deaths[\"location\"].astype(str).str.len() == 4.0) & (raw_deaths[\"location\"].astype(str).str[:1] == fips_code)]\n",
    "elif len(fips_code) == 2:\n",
    "    regional_cases = raw_cases[(raw_cases[\"location\"].astype(str).str.len() == 5.0) & (raw_cases[\"location\"].astype(str).str[:2] == fips_code)]\n",
    "    regional_deaths = raw_deaths[(raw_cases[\"location\"].astype(str).str.len() == 5.0) & (raw_deaths[\"location\"].astype(str).str[:2] == fips_code)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z_/l_q4g1892pqd5g0p2z2f66_m0000gn/T/ipykernel_28532/1507867062.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  regional_cases[\"case census\"] = 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Series.rename() got an unexpected keyword argument 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m regional_hosp \u001b[38;5;241m=\u001b[39m regional_hosp\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m regional_hosp \u001b[38;5;241m=\u001b[39m regional_hosp\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m----> 8\u001b[0m regional_hosp \u001b[38;5;241m=\u001b[39m \u001b[43mregional_hosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhosp_census\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m regional_deaths \u001b[38;5;241m=\u001b[39m regional_deaths\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m regional_deaths \u001b[38;5;241m=\u001b[39m regional_deaths\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Series.rename() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "# Set up DataFrame to hold COVID data and convert incident cases to case census and \n",
    "regional_cases[\"case census\"] = 0\n",
    "regional_cases = regional_cases.reset_index(drop = True)\n",
    "\n",
    "regional_hosp = regional_hosp.reset_index(drop = True)\n",
    "regional_hosp = regional_hosp.set_index(\"date\")\n",
    "regional_hosp = regional_hosp.groupby(\"date\")[\"value\"].sum()\n",
    "regional_hosp = regional_hosp.rename(columns={\"value\": \"hosp_census\"})\n",
    "\n",
    "regional_deaths = regional_deaths.reset_index(drop = True)\n",
    "regional_deaths = regional_deaths.set_index(\"date\")\n",
    "regional_deaths = regional_deaths.groupby(\"date\")[\"value\"].sum()\n",
    "regional_deaths = regional_deaths.rename(columns={\"value\": \"cumulative_deaths\"})\n",
    "\n",
    "covid_data_df = {}\n",
    "covid_data_df[\"date\"] = regional_cases[\"date\"].unique()\n",
    "covid_data_df[\"value\"] = regional_cases.groupby(\"date\")[\"value\"].sum()\n",
    "covid_data_df = pd.DataFrame(covid_data_df)\n",
    "covid_data_df[\"case_census\"] = covid_data_df[\"value\"].rolling(infectious_period, min_periods=1).sum()\n",
    "covid_data_df = covid_data_df.drop(columns = [\"value\"])\n",
    "covid_data_df = covid_data_df.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-06-10     0\n",
       "2020-06-11     0\n",
       "2020-06-12     0\n",
       "2020-06-13     0\n",
       "2020-06-14     0\n",
       "              ..\n",
       "2023-06-26    26\n",
       "2023-06-27    21\n",
       "2023-06-28    17\n",
       "2023-06-29    23\n",
       "2023-06-30    27\n",
       "Name: value, Length: 1092, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regional_hosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add hosp and death data to covid_data_df\n",
    "covid_data_df = pd.merge(covid_data_df, regional_hosp, how=\"inner\", left_index=True, right_index=True)\n",
    "covid_data_df = covid_data_df.drop(columns = [\"location\", \"location_name\"])\n",
    "covid_data_df\n",
    "covid_data_df = pd.merge(covid_data_df, regional_deaths, how=\"inner\", left_index=True, right_index=True)\n",
    "covid_data_df = covid_data_df.drop(columns = [\"location\", \"location_name\"])\n",
    "covid_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the DataFrame\n",
    "# covid_data_df = covid_data_df.reset_index(drop = True)\n",
    "\n",
    "# Plot the index of the dataframe and the case_census column\n",
    "# plt.plot(covid_data_df.index, covid_data_df[\"case_census\"], 'o')\n",
    "\n",
    "# Plot the index of the dataframe and the hosp_census column\n",
    "# plt.plot(covid_data_df.index, covid_data_df[\"hosp_census\"], 'o')\n",
    "\n",
    "# Plot the index of the dataframe and the cumulative deaths column\n",
    "plt.plot(covid_data_df.index, covid_data_df[\"cumulative_deaths\"], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = US_region + \"_case_hospital_death.csv\"\n",
    "covid_data_df.to_csv(filename, index = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models:\n",
    "1. You may consider any of the models you have seen in the started kit, or 6-month hackathon and evaluation scenarios.\n",
    "\n",
    "2. You may search for new models in the literature, or use TA2 model extension/transformation capabilities to modify models already in Terarium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyciemss.utils.toronto_hackathon_utils.toronto_ensemble_challenge_utils import get_case_hosp_death_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = get_case_hosp_death_data(\"MI\", 7)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
